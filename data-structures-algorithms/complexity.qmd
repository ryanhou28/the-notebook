# Complexity Analysis

## References

- [AlgoMonster - Runtime Summary](https://algo.monster/problems/runtime_summary)

## Runtime Overview

## Common Time Complexities

### O(1) - Constant

Constant time complexity. Could be

- Hashmap lookup
- Array access and update
- Pushing and popping elements from a stack
- Finding and applying math formula

### O(log(N)) - Logarithmic

$log(N)$ grows very slowly

In coding interviews, log(N) typically means:

- Binary search or variant
- Balanced binary search tree lookup
- Processing the digits of a number

Unless specified, typically log(N) refers to $log_2(N)$

Example C++:
```cpp
int N = 100000000;
while (N > 0) {
  // some constant operation
  N /= 2;
}
```

Many mainstream relational databases use binary trees for indexing by default, thus lookup by primary key in a relational database is log(N).


### O(N) - Linear

Linear time typically means looping through a linear data structure a constant number of times. Most commonly, this means:

- Going through array/linked list
- Two pointers
- Some types of greedy
- Tree/graph traversal
- Stack/Queue

Example C++:
```cpp
for (int i = 1; i <= N; i++) {
  // constant time code
}

for (int i = 1; i < 5 * N + 17; i++) {
  // constant time code
}

for (int i = 1; i < N + 538238; i++) {
  // constant time code
}
```

### O(K log(N))

- Heap push/pop K times. When you encounter problems that seek the "top K elements", you can often solve them by pushing and popping to a heap K times, resulting in an O(K log(N)) runtime. e.g., K closest points, merge K sorted lists.
- Binary search K times.

Since K is constant this kind of isn't its own time complexity and can be grouped with O(log(N))

### O(N log(N)) - Log-Linear

- Sorting. The default sorting algorithm's expected runtime in all mainstream languages is N log(N). For example, java uses a variant of merge sort for object sorting and a variant of Quick Sort for primitive type sorting.
- Divide and conquer with a linear time merge operation. Divide is normally log(N), and if merge is O(N) then the overall runtime is O(N log(N)). An example problem is smaller numbers to the right.

### O(N^2) - Quadratic


- Nested loops, e.g., visiting each matrix entry
- Many brute force solutions

```cpp
for (int i = 1; i <= N; i++) {
  for (int j = 1; j <= N; j++) {
    // constant time code
  }
}
```

### O(2^N) - Exponential
Grows very rapidly. Often requires memoization to avoid repeated computations and reduce complexity.

- Combinatorial problems, backtracking, e.g. subsets
- Often involves recursion and is harder to analyze time complexity at first sight

E.g.: A recursive Fibonacci algorithm is $O(2^N)$

```cpp
int Fib(int n) {
  if (n == 0 || n == 1) {
    return 1;
  }
  return Fib(n - 1) + Fib(n - 2);
}
```

### O(N!) - Factorial

Grows very very rapidly. Only solvable by computers for small N. Often requires memoization to avoid repeated computations and reduce complexity.

- Combinatorial problems, backtracking, e.g. permutations
- Often involves recursion and is harder to analyze time complexity at first sight


## Amortized Time Complexity